{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dr1qwCeaTpx"
   },
   "source": [
    "#### Some regular code to check the necessary resources information and connect to google drive to access dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDVUwO6Phyzd",
    "outputId": "8adce37a-1a9a-4dfc-f0a5-1ef4ed45672f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11648514387832933052\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3665166336\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2784685498216898728\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# # to check the devices information\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "# # device_name = tf.test.gpu_device_name()\n",
    "# # if device_name != '/device:GPU:0':\n",
    "# #   raise SystemError('GPU device not found')\n",
    "# # print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5D2FyhFjusr",
    "outputId": "67e67cf1-31e9-42f1-d06a-0272ce440379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "   raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QO3gA_SMjuud",
    "outputId": "085f9197-b5e4-479b-dfef-f57a5db5804d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gputil in c:\\users\\akkir\\anaconda3\\envs\\tensorflow\\lib\\site-packages (1.4.0)\n",
      "Gen RAM Free: 8.1 GB  | Proc size: 698.0 MB\n",
      "GPU RAM Free: 5799MB | Used: 345MB | Util   6% | Total 6144MB\n"
     ]
    }
   ],
   "source": [
    "# memory footprint support libraries/code\n",
    "#!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "#!pip install psutil\n",
    "#!pip install humanize\n",
    "import psutil\n",
    "\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4P17ihsPi_Bh"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMiwqP4XV3AD",
    "outputId": "5c9aa242-3b58-4a5d-b728-f56c62754806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.6.0\n",
      "Keras version:  2.6.0\n",
      "GPU:  /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 1.x\n",
    "import os\n",
    "# import keras\n",
    "import json\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "\n",
    "# from keras import backend as K\n",
    "# from keras.engine import Input, Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv3D,\n",
    "    MaxPooling3D,\n",
    "    concatenate,\n",
    "    UpSampling3D,\n",
    "    Dropout,\n",
    "    Activation,\n",
    "    Conv3DTranspose,\n",
    "    Concatenate,\n",
    "    LayerNormalization,\n",
    "    #BatchNormalization,\n",
    ")\n",
    "\n",
    "from tensorflow_addons.layers import (\n",
    "    GroupNormalization,\n",
    ")   \n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    CSVLogger,\n",
    "    EarlyStopping,\n",
    "    TensorBoard,\n",
    "    TerminateOnNaN,\n",
    ")\n",
    "# from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.compat.v1.logging import INFO, set_verbosity\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "set_verbosity(INFO)\n",
    "\n",
    "K.set_image_data_format(\"channels_first\")\n",
    "\n",
    "\n",
    "import random as python_random\n",
    "np.random.seed(2021)\n",
    "python_random.seed(2021)\n",
    "tf.random.set_seed(2021)\n",
    "\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "print('Keras version: ', keras.__version__)\n",
    "print('GPU: ', tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFdT7OVqQrlB"
   },
   "source": [
    "## Run external python files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LVoekHE9QpVe"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\\\import_files\")\n",
    "import visualize\n",
    "import losses_and_metrics as lnm\n",
    "import custom_data_generator as data_gen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5RCYWtej1mJ"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6VLuBT39j09z"
   },
   "outputs": [],
   "source": [
    "# directory settings\n",
    "#HOME_DIR = \"/content/drive/My Drive/Thesis_Experiment/BraTS_Dataset/\"\n",
    "dir_train = \"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Dataset\\\\image_train\"\n",
    "dir_train_label = \"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Dataset\\\\label_train\"\n",
    "dir_valid = \"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Dataset\\\\image_valid\"\n",
    "dir_valid_label = \"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Dataset\\\\label_valid\"\n",
    "\n",
    "\n",
    "processed_dir = \"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\h5_data_B1\"\n",
    "checkpoint_path = os.path.join(processed_dir, '\\checkpoints\\chckpt-1-{epoch:03d}.ckpt')\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "# unet model settingsD:\\Akhilesh_PHD\\Thesis Experiment\\BraTS\\h5_dataset_stand_LN\n",
    "dim = (160, 160, 16)\n",
    "padding = 'same'\n",
    "activation = 'relu'\n",
    "data_format = 'channels_first'\n",
    "#data_format = 'channels_last'\n",
    "n_channels = 4\n",
    "kernel_size = (3,3,3)\n",
    "strides = (1,1,1)\n",
    "pool_size = (2,2,2)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "# training settings\n",
    "config_path = \"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\h5_data_B1\"\n",
    "with open(config_path + \"\\config_dataset.json\") as json_file:\n",
    "    number_dataset = json.load(json_file)\n",
    "\n",
    "batch_size = 2\n",
    "steps_per_epoch = len(number_dataset['train']) // batch_size\n",
    "n_epochs = 100\n",
    "validation_steps = len(number_dataset['valid']) // batch_size\n",
    "reduce_factor = 0.1\n",
    "patience_reduce_lr = 5\n",
    "patience_earlystopping = 10\n",
    "min_lr = 0.0000001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZtjg7rgjHhy"
   },
   "source": [
    "# Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DSroi0OC7WZU"
   },
   "outputs": [],
   "source": [
    "# function to load the data\n",
    "def load_case(image_nifty_file, label_nifty_file):\n",
    "    # load the image and label file, get the image content \n",
    "    # and return a numpy array for each\n",
    "    image = np.array(nib.load(image_nifty_file).get_fdata())\n",
    "    label = np.array(nib.load(label_nifty_file).get_fdata())\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def visualize_patch_predict(image, ground_truth, prediction):\n",
    "\tfig, ax = plt.subplots(1, 3, figsize=[10,5], squeeze=False)\n",
    "\tax[0][0].imshow(image[:, :, 0], cmap='Greys_r')\n",
    "\tax[0][0].set_title('Image')\n",
    "\tax[0][0].set_yticks([])\n",
    "\tax[0][0].set_xticks([])\n",
    "\n",
    "\tax[0][1].imshow(ground_truth[:, :, 0], cmap='Greys_r')\n",
    "\tax[0][1].set_title('Ground Truth')\n",
    "\tax[0][1].set_xticks([])\n",
    "\tax[0][1].set_yticks([])\n",
    "\n",
    "\tax[0][2].imshow(prediction[:, :, 0], cmap='Greys_r')\n",
    "\tax[0][2].set_title('Prediction')\n",
    "\tax[0][2].set_xticks([])\n",
    "\tax[0][2].set_yticks([])\n",
    "\n",
    "\tfig.subplots_adjust(wspace=0, hspace=0)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99Dwk-cprpdk"
   },
   "source": [
    "# Code to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "zWEfYdrvkVZu",
    "outputId": "65e61d58-fe98-4ee4-e9dd-14e689f1312c"
   },
   "outputs": [],
   "source": [
    "#image, label = load_case('D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Dataset\\\\image_train\\BRATS_002.nii.gz', 'D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Dataset\\\\label_train\\BRATS_002.nii.gz')\n",
    "# uncomment below code to see the grid\n",
    "# image = get_labeled_image(image, label)\n",
    "# plot_image_grid(image)\n",
    "\n",
    "# some general information of the loaded image and label\n",
    "#print('Image_min:', np.min(image), '\\t\\t\\t\\t Label_min:', np.min(label))\n",
    "#print('Image_max:', np.max(image), '\\t\\t\\t Label_max:', np.max(label))\n",
    "#print('Image_dim:', image.shape, '\\t\\t Label_dim:', label.shape)\n",
    "#print('Image_type:', type(image), '\\t Label_type:', type(label))\n",
    "# to visualize the gif\n",
    "#print('\\n\\nSagittal \\t\\t Coronal \\t\\t Axial')\n",
    "#visualize.visualize_data_gif(visualize.get_labeled_image(image, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-LCPXxCqD2B"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PsShoIiyVzYh"
   },
   "outputs": [],
   "source": [
    "conv_pars = dict(kernel_size=kernel_size, padding=padding, data_format=data_format)\n",
    "max_pool_pars = dict(pool_size=pool_size, data_format=data_format)\n",
    "\n",
    "input = Input(shape=(n_channels, dim[0], dim[1], dim[2]))\n",
    "\n",
    "# down sampling\n",
    "c1 = Conv3D(32, strides=strides, **conv_pars)(input)\n",
    "c1 = GroupNormalization(groups=2)(c1)\n",
    "c1 = Activation(activation) (c1)\n",
    "c1 = Dropout(0.25)(c1)\n",
    "c1 = Conv3D(64, strides=strides, **conv_pars)(c1)\n",
    "c1 = GroupNormalization(groups=2)(c1)\n",
    "c1 = Activation(activation) (c1)\n",
    "p1 = MaxPooling3D(**max_pool_pars)(c1)\n",
    "\n",
    "c2 = Conv3D(64, strides=strides, **conv_pars)(p1)\n",
    "c2 = GroupNormalization(groups=2)(c2)\n",
    "c2 = Activation(activation)(c2)\n",
    "c2 = Dropout(0.25)(c2)\n",
    "c2 = Conv3D(128, strides=strides, **conv_pars)(c2)\n",
    "c2 = GroupNormalization(groups=2)(c2)\n",
    "c2 = Activation(activation)(c2)\n",
    "p2 = MaxPooling3D(**max_pool_pars)(c2)\n",
    "\n",
    "\n",
    "c3 = Conv3D(128, strides=strides, **conv_pars)(p2)\n",
    "c3 = GroupNormalization(groups=2)(c3)\n",
    "c3 = Activation(activation)(c3)\n",
    "c3 = Dropout(0.25)(c3)\n",
    "c3 = Conv3D(256, strides=strides, **conv_pars)(c3)\n",
    "c3 = GroupNormalization(groups=2)(c3)\n",
    "c3 = Activation(activation)(c3)\n",
    "p3 = MaxPooling3D(**max_pool_pars)(c3)\n",
    "\n",
    "\n",
    "c4 = Conv3D(256, strides=strides, **conv_pars)(p3)\n",
    "c4 = GroupNormalization(groups=2)(c4)\n",
    "c4 = Activation(activation)(c4)\n",
    "c4 = Dropout(0.25)(c4)\n",
    "c4 = Conv3D(512, strides=strides, **conv_pars)(c4)\n",
    "c4 = GroupNormalization(groups=2)(c4)\n",
    "c4 = Activation(activation)(c4)\n",
    "\n",
    "# # up sampling\n",
    "u2 = UpSampling3D(size=pool_size, data_format=data_format)(c4)\n",
    "u2 = concatenate([u2, c3], axis=1)\n",
    "u2 = Conv3D(256, strides=strides, **conv_pars)(u2)\n",
    "u2 = GroupNormalization(groups=2)(u2)\n",
    "u2 = Activation(activation)(u2)\n",
    "u2 = Dropout(0.25)(u2)\n",
    "u2 = Conv3D(256, strides=strides, **conv_pars)(u2)\n",
    "u2 = GroupNormalization(groups=2)(u2)\n",
    "u2 = Activation(activation)(u2)\n",
    "\n",
    "u1 = UpSampling3D(size=pool_size, data_format=data_format)(u2)\n",
    "u1 = concatenate([u1, c2], axis=1)\n",
    "u1 = Conv3D(128, strides=strides, **conv_pars)(u1)\n",
    "u1 = GroupNormalization(groups=2)(u1)\n",
    "u1 = Activation(activation)(u1)\n",
    "u1 = Dropout(0.25)(u1)\n",
    "u1 = Conv3D(128, strides=strides, **conv_pars)(u1)\n",
    "u1 = GroupNormalization(groups=2)(u1)\n",
    "u1 = Activation(activation)(u1)\n",
    "\n",
    "\n",
    "u0 = UpSampling3D(size=pool_size, data_format=data_format)(u1)\n",
    "u0 = concatenate([u0, c1], axis=1)\n",
    "u0 = Conv3D(64, strides=strides, **conv_pars)(u0)\n",
    "u0 = GroupNormalization(groups=2)(u0)\n",
    "u0 = Activation(activation)(u0)\n",
    "u0 = Dropout(0.25)(u0)\n",
    "u0 = Conv3D(64, strides=strides, **conv_pars)(u0)\n",
    "u0 = GroupNormalization(groups=2)(u0)\n",
    "u0 = Activation(activation)(u0)\n",
    "\n",
    "output = Conv3D(3, (1,1,1), activation='sigmoid', data_format=data_format)(u0)\n",
    "\n",
    "model = Model(inputs=input, outputs=output, name=f\"UNET-depth4-{data_format}\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss=lnm.soft_dice_loss, \n",
    "              metrics=[lnm.dice_coefficient])\n",
    "\n",
    "#model.summary(line_length=135)\n",
    "\n",
    "# saving the architecture in text file\n",
    "with open((\"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\\\h5_data_B1\\\\model_summary-1.txt\"), 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary(line_length=135)\n",
    "\n",
    "# saving the architecture format in png\n",
    "keras.utils.plot_model(model, \n",
    "                       to_file= \"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\\\h5_data_B1\\\\model_image-1.png\", \n",
    "                       show_shapes=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2Umq2c4tTTX",
    "outputId": "bb2649e9-9cf1-4254-c482-443889d7d4a6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9PUA26xqnjM",
    "outputId": "d5524de9-946a-48e0-85da-f3c6823b032e"
   },
   "outputs": [],
   "source": [
    "#import json\n",
    "#with open(\"D:\\Akhilesh_PHD\\Thesis Experiment\\BraTS\\h5_dataset_stand_LN\\config_dataset.json\") as json_file:\n",
    "#    config = json.load(json_file)\n",
    "\n",
    "# Get generators for training and validation sets\n",
    "#train_generator = data_gen.VolumeDataGenerator(config[\"train\"],\"D:\\Akhilesh_PHD\\Thesis Experiment\\BraTS\\h5_dataset_stand_LN\\train\",batch_size=batch_size, dim=dim,verbose=0)\n",
    "#valid_generator = data_gen.VolumeDataGenerator(config[\"valid\"],\"D:\\Akhilesh_PHD\\Thesis Experiment\\BraTS\\h5_dataset_stand_LN\\valid\",batch_size=batch_size, dim=dim,verbose=0)\n",
    "#checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_dice_coefficient', save_weights_only=True, mode='max', verbose=1)\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_factor, patience=patience_reduce_lr, min_lr=min_lr, mode='auto')\n",
    "#csvlogger = CSVLogger((\"D:\\Akhilesh_PHD\\Thesis Experiment\\BraTS\\h5_dataset_stand_LN\\training_log_1.csv\"), separator=',', append=False)\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=patience_earlystopping, verbose=1, mode='auto')\n",
    "#terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "#callbacks = [checkpoint, reduce_lr, csvlogger, early_stopping, terminate_on_nan]\n",
    "\n",
    "#history = model.fit(x=train_generator, steps_per_epoch=steps_per_epoch, epochs=n_epochs, validation_data=valid_generator, validation_steps=validation_steps, callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " failed to allocate memory\n\t [[node UNET-depth4-channels_first/dropout_6/dropout/GreaterEqual (defined at <ipython-input-12-fa8282d60178>:34) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_11646]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-fa8282d60178>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                     callbacks=callbacks)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  failed to allocate memory\n\t [[node UNET-depth4-channels_first/dropout_6/dropout/GreaterEqual (defined at <ipython-input-12-fa8282d60178>:34) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_11646]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "with open(\"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\h5_data_B1\\config_dataset.json\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "train_generator = data_gen.VolumeDataGenerator(config[\"train\"],\n",
    "                                               \"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\h5_data_B1\\\\train\\\\\",\n",
    "                                               batch_size=batch_size, dim=dim,\n",
    "                                               verbose=0)\n",
    "valid_generator = data_gen.VolumeDataGenerator(config[\"valid\"],\n",
    "                                               \"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\h5_data_B1\\\\valid\\\\\",\n",
    "                                               batch_size=batch_size, dim=dim,\n",
    "                                               verbose=0)\n",
    "checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_dice_coefficient',\n",
    "                             save_weights_only=True,\n",
    "                             mode='max',\n",
    "                             verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_factor, \n",
    "                              patience=patience_reduce_lr,\n",
    "                              min_lr=min_lr, mode='auto')\n",
    "csvlogger = CSVLogger((\"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\h5_data_B1\\\\training_log_1.csv\"),\n",
    "                      separator=',', append=False)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                               patience=patience_earlystopping, \n",
    "                               verbose=1, \n",
    "                               mode='auto')\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr, csvlogger, terminate_on_nan]\n",
    "\n",
    "history = model.fit(x=train_generator, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    epochs=n_epochs, \n",
    "                    validation_data=valid_generator, \n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\h5_data_B1\\model-1_entire_state_GN_100_1\\assets\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "now = 2022-08-01 19:29:16.584918\n",
      "date and time = 01/08/2022 19:29:16\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------')\n",
    "# to save the model weights explicitly\n",
    "model.save_weights(\"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\h5_data_B1\\model-1_weights_GN_100_1.h5\")\n",
    "#print(f\"The model weights has been saved to {\"D:\\Akhilesh_PHD\\Thesis Experiment\\BraTS\\h5_dataset_stand_LN\"} as \\'model-1_weights_LN_25.h5\\'\")\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "# model into JSON string\n",
    "json_config = model.to_json()\n",
    "with open(\"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\h5_data_B1\\model-1_to_json_GN_100_1.json\", 'w') as json_file:\n",
    "    json_file.write(json_config)\n",
    "#print(f\"The model JSON configuration has been saved to {\"D:\\Akhilesh_PHD\\Thesis Experiment\\BraTS\\h5_dataset_stand_LN\"} as \\'model-1_to_json_LN_25.json\\'\")\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "# to save an entire model\n",
    "model.save(\"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\h5_data_B1\\model-1_entire_state_GN_100_1\", include_optimizer=True, save_format='tf')\n",
    "#print(f\"The model has been saved to {\"D:\\Akhilesh_PHD\\Thesis Experiment\\BraTS\\h5_dataset_stand_LN\"} as \\'model-1_entire_state_LN_25\\'.\")\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "model.save(\"D:\\Akhilesh_PHD\\Brain\\BraTS_2020_New1\\Batch_Normalization\\h5_data_B1\\model-1_entire_state_GN_100_1.h5\")\n",
    "#print(f\"The model has been saved to {\"D:\\Akhilesh_PHD\\Thesis Experiment\\BraTS\\h5_dataset_stand_LN\"} as \\'model-1_entire_state_LN_25\\'.\")\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    " \n",
    "print(\"now =\", now)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"date and time =\", dt_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9nL2UdNTJY8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QxXphxRLFXwJ"
   ],
   "name": "Stand_LayerNorm_tumorSegment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
